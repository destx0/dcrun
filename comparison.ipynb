{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlist import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "savefile = \"data.json\"\n",
    "points_count = 100\n",
    "to_plot = False\n",
    "noise = 0.1\n",
    "dataset_types = [\"circles\", \"moons\", \"blobs\"]\n",
    "dataset_type = dataset_types[2]\n",
    "dataset_sizes = [1000, 3000, 5000, 10000, 15000]\n",
    "dataset_types = [\"circles\", \"moons\", \"blobs\"]\n",
    "noise = 0.1\n",
    "no_centres = 1\n",
    "filename = \"mst_results.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/voy/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/voy/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/voy/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/voy/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/voy/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/voy/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/voy/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/home/voy/.local/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 111\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m size \u001b[38;5;129;01min\u001b[39;00m dataset_sizes:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset_type \u001b[38;5;129;01min\u001b[39;00m dataset_types:\n\u001b[0;32m--> 111\u001b[0m         experiment_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_mst_algorithms\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_centres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m         all_experiment_results\u001b[38;5;241m.\u001b[39mextend(experiment_results)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# Prepare data for tabulate\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 62\u001b[0m, in \u001b[0;36mevaluate_mst_algorithms\u001b[0;34m(dataset_type, points_count, noise, no_centres, filename, runs)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Measure runtime for Prim's MST\u001b[39;00m\n\u001b[1;32m     61\u001b[0m start_time \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 62\u001b[0m prim_weight, prim_edge_count, final_graph \u001b[38;5;241m=\u001b[39m \u001b[43mmst_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_mst\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprim\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     64\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m end_time \u001b[38;5;241m=\u001b[39m tm\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     66\u001b[0m prim_runtime \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/space/cud/dcrun/kmist.py:486\u001b[0m, in \u001b[0;36mMST.apply_mst\u001b[0;34m(self, algorithm, to_plot)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkmist(to_plot\u001b[38;5;241m=\u001b[39mto_plot)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprim\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprim_mst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_plot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mto_plot\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m algorithm \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmst\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmst(to_plot\u001b[38;5;241m=\u001b[39mto_plot)\n",
      "File \u001b[0;32m~/space/cud/dcrun/kmist.py:213\u001b[0m, in \u001b[0;36mMST.prim_mst\u001b[0;34m(self, to_plot)\u001b[0m\n\u001b[1;32m    206\u001b[0m     total_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meuclidean_distance(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints[u], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints[parent[u]]\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    212\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m in_mst[v]\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meuclidean_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mu\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;241m<\u001b[39m min_edge[v]\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[1;32m    216\u001b[0m         min_edge[v] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meuclidean_distance(\n\u001b[1;32m    217\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints[u], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoints[v]\n\u001b[1;32m    218\u001b[0m         )\n\u001b[1;32m    219\u001b[0m         parent[v] \u001b[38;5;241m=\u001b[39m u\n",
      "File \u001b[0;32m~/space/cud/dcrun/kmist.py:473\u001b[0m, in \u001b[0;36mMST.euclidean_distance\u001b[0;34m(point1, point2)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meuclidean_distance\u001b[39m(point1, point2):\n\u001b[0;32m--> 473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoint2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/linalg/linalg.py:2512\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2511\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdot(x)\n\u001b[0;32m-> 2512\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m   2514\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mreshape(ndim\u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time as tm\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "# Function to append results to JSON file\n",
    "def append_results_to_json(result, filename):\n",
    "    with open(filename, \"a\") as f:\n",
    "        json.dump(result, f, indent=4)\n",
    "        f.write(\"\\n\")  # Add a newline to separate entries\n",
    "\n",
    "\n",
    "# Function to generate and evaluate MST algorithms\n",
    "def evaluate_mst_algorithms(\n",
    "    dataset_type, points_count, noise, no_centres, filename, runs=2\n",
    "):\n",
    "    all_results = []\n",
    "    for run in range(runs):\n",
    "        points = generate_dataset(\n",
    "            dataset_type=dataset_type,\n",
    "            points_count=points_count,\n",
    "            noise=noise,\n",
    "            no_centres=no_centres,\n",
    "            to_plot=False,\n",
    "        )\n",
    "        mst_builder = MST(points)\n",
    "\n",
    "        results = {\n",
    "            \"dataset_type\": dataset_type,\n",
    "            \"points_count\": points_count,\n",
    "            \"run\": run + 1,\n",
    "        }\n",
    "\n",
    "        # Measure runtime for K-MSTree\n",
    "        start_time = tm.time()\n",
    "        mst_weight, edge_count, final_graph = mst_builder.apply_mst(\n",
    "            algorithm=\"kmistree\", to_plot=False\n",
    "        )\n",
    "        end_time = tm.time()\n",
    "        kmistree_runtime = end_time - start_time\n",
    "        results[\"kmistree\"] = {\n",
    "            \"weight\": mst_weight,\n",
    "            \"edge_count\": edge_count,\n",
    "            \"runtime\": kmistree_runtime,\n",
    "        }\n",
    "\n",
    "        # Measure runtime for K-MST\n",
    "        start_time = tm.time()\n",
    "        mst_weight, edge_count, final_graph = mst_builder.apply_mst(\n",
    "            algorithm=\"kmist\", to_plot=False\n",
    "        )\n",
    "        end_time = tm.time()\n",
    "        kmist_runtime = end_time - start_time\n",
    "        results[\"kmist\"] = {\n",
    "            \"weight\": mst_weight,\n",
    "            \"edge_count\": edge_count,\n",
    "            \"runtime\": kmist_runtime,\n",
    "        }\n",
    "\n",
    "        # Measure runtime for Prim's MST\n",
    "        start_time = tm.time()\n",
    "        prim_weight, prim_edge_count, final_graph = mst_builder.apply_mst(\n",
    "            algorithm=\"prim\", to_plot=False\n",
    "        )\n",
    "        end_time = tm.time()\n",
    "        prim_runtime = end_time - start_time\n",
    "        results[\"prim\"] = {\n",
    "            \"weight\": prim_weight,\n",
    "            \"edge_count\": prim_edge_count,\n",
    "            \"runtime\": prim_runtime,\n",
    "        }\n",
    "\n",
    "        # Measure runtime for FMST\n",
    "        start_time = tm.time()\n",
    "        mst_weight, edge_count, final_graph = mst_builder.apply_mst(\n",
    "            algorithm=\"fmst\", to_plot=False\n",
    "        )\n",
    "        end_time = tm.time()\n",
    "        fmst_runtime = end_time - start_time\n",
    "        results[\"fmst\"] = {\n",
    "            \"weight\": mst_weight,\n",
    "            \"edge_count\": edge_count,\n",
    "            \"runtime\": fmst_runtime,\n",
    "        }\n",
    "\n",
    "        # Calculate errors compared to Prim's MST\n",
    "        for key in [\"kmistree\", \"kmist\", \"fmst\"]:\n",
    "            results[key][\"weight_error\"] = abs(\n",
    "                results[key][\"weight\"] - results[\"prim\"][\"weight\"]\n",
    "            )\n",
    "            results[key][\"edge_count_error\"] = (\n",
    "                results[\"prim\"][\"edge_count\"] / results[key][\"edge_count\"]\n",
    "            )\n",
    "            results[key][\"runtime_error\"] = (\n",
    "                results[\"prim\"][\"runtime\"] / results[key][\"runtime\"]\n",
    "            )\n",
    "\n",
    "        all_results.append(results)\n",
    "        append_results_to_json(results, filename)\n",
    "\n",
    "    return all_results\n",
    "\n",
    "\n",
    "# Dataset parameters\n",
    "\n",
    "\n",
    "# Run experiments for different dataset sizes and types\n",
    "all_experiment_results = []\n",
    "for size in dataset_sizes:\n",
    "    for dataset_type in dataset_types:\n",
    "        experiment_results = evaluate_mst_algorithms(\n",
    "            dataset_type, size, noise, no_centres, filename\n",
    "        )\n",
    "        all_experiment_results.extend(experiment_results)\n",
    "\n",
    "# Prepare data for tabulate\n",
    "table = []\n",
    "headers = [\n",
    "    \"Dataset Type\",\n",
    "    \"Points Count\",\n",
    "    \"Run\",\n",
    "    \"Algorithm\",\n",
    "    \"Weight\",\n",
    "    \"Edge Count\",\n",
    "    \"Runtime (s)\",\n",
    "    \"Weight Error\",\n",
    "    \"Edge Count Ratio\",\n",
    "    \"Runtime Ratio\",\n",
    "]\n",
    "\n",
    "for result in all_experiment_results:\n",
    "    for key, value in result.items():\n",
    "        if key not in [\"dataset_type\", \"points_count\", \"run\"]:\n",
    "            row = [\n",
    "                result[\"dataset_type\"],\n",
    "                result[\"points_count\"],\n",
    "                result[\"run\"],\n",
    "                key,\n",
    "                value[\"weight\"],\n",
    "                value[\"edge_count\"],\n",
    "                value[\"runtime\"],\n",
    "                value.get(\"weight_error\", 0),\n",
    "                value.get(\"edge_count_error\", 0),\n",
    "                value.get(\"runtime_error\", 0),\n",
    "            ]\n",
    "            table.append(row)\n",
    "\n",
    "# Print results using tabulate\n",
    "print(tabulate(table, headers, tablefmt=\"grid\"))\n",
    "\n",
    "# Print results for verification\n",
    "print(json.dumps(all_experiment_results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 35 column 1 (char 951)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load results from JSON file\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mload_results_from_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmst_results.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Prepare data for tabulate\u001b[39;00m\n\u001b[1;32m     14\u001b[0m table \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m, in \u001b[0;36mload_results_from_json\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_results_from_json\u001b[39m(filename):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 7\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.10/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 35 column 1 (char 951)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Function to load results from JSON file\n",
    "def load_results_from_json(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        results = json.load(f)\n",
    "    return results\n",
    "\n",
    "# Load results from JSON file\n",
    "results = load_results_from_json(\"mst_results.json\")\n",
    "\n",
    "# Prepare data for tabulate\n",
    "table = []\n",
    "headers = [\n",
    "    \"Dataset Type\",\n",
    "    \"Points Count\",\n",
    "    \"Run\",\n",
    "    \"Algorithm\",\n",
    "    \"Weight\",\n",
    "    \"Edge Count\",\n",
    "    \"Runtime (s)\",\n",
    "    \"Weight Error\",\n",
    "    \"Edge Count Ratio\",\n",
    "    \"Runtime Ratio\",\n",
    "]\n",
    "\n",
    "for result in results:\n",
    "    for key, value in result.items():\n",
    "        if key not in [\"dataset_type\", \"points_count\", \"run\"]:\n",
    "            row = [\n",
    "                result[\"dataset_type\"],\n",
    "                result[\"points_count\"],\n",
    "                result[\"run\"],\n",
    "                key,\n",
    "                value[\"weight\"],\n",
    "                value[\"edge_count\"],\n",
    "                value[\"runtime\"],\n",
    "                value.get(\"weight_error\", 0),\n",
    "                value.get(\"edge_count_error\", 0),\n",
    "                value.get(\"runtime_error\", 0),\n",
    "            ]\n",
    "            table.append(row)\n",
    "\n",
    "# Print results using tabulate\n",
    "print(tabulate(table, headers, tablefmt=\"grid\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
