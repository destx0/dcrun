{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_blobs\n",
    "import random\n",
    "import json\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from kdtree import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "savefile = \"data.json\"\n",
    "points_count = 5000\n",
    "to_plot = False\n",
    "no_centres = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the parameters\n",
    "from sklearn.datasets import make_circles\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the parameters\n",
    "noise = 0.05  # Amount of noise\n",
    "\n",
    "# Generate the data\n",
    "X, y = make_circles(n_samples=points_count, noise=noise, factor=0.5, random_state=42)\n",
    "\n",
    "# Convert the data to a list of tuples\n",
    "points = [(x, y) for x, y in X]\n",
    "# points = [(round(x , 1), round(y , 1)) for x, y in X]\n",
    "maxdis = math.ceil(math.log2(points_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = make_blobs(n_samples=points_count, centers=no_centres, random_state=42)\n",
    "points = [(x, y) for x, y in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcran_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build():\n",
    "    tree = KDTree()\n",
    "    tree.root = tree.build(points)\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for point in points:\n",
    "        G.add_node(point , pos = point)\n",
    "\n",
    "    neighbours = {}\n",
    "    maxdis = math.ceil(math.log2(points_count))\n",
    "    for point in points:\n",
    "        neighbours[point] = i_neighbors(tree, point, maxdis)\n",
    "    return  G,  neighbours\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_comps(core1 , core2, core_points_map , mst):\n",
    "    pivot2 = min(core_points_map[core2], key=lambda node: euclidean_distance(node, core1))\n",
    "    pivot1 = min(core_points_map[core1], key=lambda node: euclidean_distance(node, pivot2))\n",
    "    mst.add_edge(pivot1, pivot2 , weight = euclidean_distance(pivot1, pivot2))\n",
    "    print(f\"merging {core1} and {core2} with pivot {pivot1} and {pivot2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_phase(G):\n",
    "    core_points_map = {}\n",
    "    for component in nx.connected_components(G):\n",
    "        centroid = np.mean([node for node in component], axis=0)\n",
    "        closest_point = min(component, key=lambda node: euclidean_distance(node, centroid))\n",
    "        core_points_map[closest_point] = component\n",
    "\n",
    "    core_points = list(core_points_map.keys())\n",
    "\n",
    "    minc = [float(\"inf\")] * len(core_points[0])\n",
    "    maxc = [float(\"-inf\")] * len(core_points[0])\n",
    "\n",
    "    for point in core_points:\n",
    "        for i in range(len(point)):\n",
    "            minc[i] = min(minc[i], point[i])\n",
    "            maxc[i] = max(maxc[i], point[i])\n",
    "\n",
    "    diff = [maxc[i] - minc[i] for i in range(len(minc))]\n",
    "    min_diff_axis = diff.index(max(diff))\n",
    "\n",
    "    sorted_core_points = sorted(core_points, key=lambda point: point[min_diff_axis])\n",
    "    for core1 , core2 in zip(sorted_core_points, sorted_core_points[1:]):\n",
    "        merge_comps(core1, core2, core_points_map, G)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcrun():\n",
    "    G,   neighbours = build()\n",
    "    print(G.number_of_nodes() , G.number_of_edges())\n",
    "    k = 0\n",
    "    while ( k   < maxdis) :\n",
    "        print(\"Connected Components : \" , len(list(nx.connected_components(G))))\n",
    "        print(\n",
    "            f\"The graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\"\n",
    "        )\n",
    "\n",
    "        if(len(connected_components := list(nx.connected_components(G)))) == 1 : break\n",
    "        for component in connected_components:\n",
    "            for node in component:\n",
    "                wt , pos = neighbours[node][k]\n",
    "                if pos in component : continue\n",
    "                G.add_edge(node , pos , weight = wt)\n",
    "        k += 1\n",
    "    else :\n",
    "        print(\"merge phase\")\n",
    "        merge_phase(G)\n",
    "        print(\n",
    "            f\"The graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\"\n",
    "        )\n",
    "        print(\"Connected Components : \" , len(list(nx.connected_components(G))))\n",
    "    edgecount = G.number_of_edges()\n",
    "    mst = nx.minimum_spanning_tree(G)    \n",
    "    print(mst.number_of_nodes() , mst.number_of_edges())\n",
    "    mst_weight = sum(data[\"weight\"] for u, v, data in mst.edges(data=True)) \n",
    "    print(\n",
    "        f\"Minimum Spanning Tree: {mst.number_of_nodes()} nodes, {mst.number_of_edges()} edges, Total Weight: {mst_weight}\"\n",
    "    )\n",
    "    return mst_weight , edgecount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 0\n",
      "Connected Components :  5000\n",
      "The graph has 5000 nodes and 0 edges.\n",
      "Connected Components :  1541\n",
      "The graph has 5000 nodes and 3459 edges.\n",
      "Connected Components :  224\n",
      "The graph has 5000 nodes and 5401 edges.\n",
      "Connected Components :  12\n",
      "The graph has 5000 nodes and 5947 edges.\n",
      "Connected Components :  1\n",
      "The graph has 5000 nodes and 5995 edges.\n",
      "5000 4999\n",
      "Minimum Spanning Tree: 5000 nodes, 4999 edges, Total Weight: 224.23808964504997\n"
     ]
    }
   ],
   "source": [
    "mst_weight, edgecount = dcrun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcran_end_time = time.time()\n",
    "dcran_elapsed_time = dcran_end_time - dcran_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gst = nx.Graph()\n",
    "\n",
    "# for pointi in points:\n",
    "#     Gst.add_node(pointi, pos=pointi)\n",
    "    \n",
    "# for pointi in points:    \n",
    "#     for pointj in points:\n",
    "#         if pointi != pointj:\n",
    "#             dis = euclidean_distance(pointi, pointj)\n",
    "#             Gst.add_edge(pointi , pointj , weight=dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gst = nx.minimum_spanning_tree(Gst, algorithm=\"prim\", weight=\"weight\")\n",
    "# gst_weight = sum(data[\"weight\"] for u, v, data in Gst.edges(data=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_end_time = time.time()\n",
    "prim_elapsed_time = prim_end_time - prim_start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MST Weight:  221.68865919201852\n",
      "time taken by dcran :  7.015679836273193\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "eprim_start_time = time.time()\n",
    "def calculate_distance(p1, p2):\n",
    "    x1, y1 = p1\n",
    "    x2, y2 = p2\n",
    "    return math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "\n",
    "\n",
    "def prim_mst(points):\n",
    "    n = len(points)\n",
    "    visited = [False] * n\n",
    "    min_cost = [float(\"inf\")] * n\n",
    "    parent = [None] * n\n",
    "\n",
    "    min_cost[0] = 0\n",
    "    parent[0] = -1\n",
    "\n",
    "    for _ in range(n):\n",
    "        min_index = -1\n",
    "        for i in range(n):\n",
    "            if not visited[i] and (\n",
    "                min_index == -1 or min_cost[i] < min_cost[min_index]\n",
    "            ):\n",
    "                min_index = i\n",
    "\n",
    "        visited[min_index] = True\n",
    "\n",
    "        for i in range(n):\n",
    "            if not visited[i]:\n",
    "                distance = calculate_distance(points[min_index], points[i])\n",
    "                if distance < min_cost[i]:\n",
    "                    min_cost[i] = distance\n",
    "                    parent[i] = min_index\n",
    "\n",
    "    mst_edges = []\n",
    "    for i in range(1, n):\n",
    "        mst_edges.append((parent[i], i))\n",
    "\n",
    "    return mst_edges\n",
    "\n",
    "\n",
    "mst = prim_mst(points)\n",
    "eprim_end_time = time.time()\n",
    "eprim_elapsed_time = eprim_end_time - eprim_start_time\n",
    "print(\"MST Weight: \", eprim_wt := sum([calculate_distance(points[u], points[v]) for u, v in mst]))\n",
    "print(\"time taken by dcran : \", eprim_elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speedup: 10.14\n"
     ]
    }
   ],
   "source": [
    "speedup = eprim_elapsed_time / dcran_elapsed_time\n",
    "print(f\"Speedup: {speedup:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Error: 1.1500049043208953%\n"
     ]
    }
   ],
   "source": [
    "wt_error = abs(mst_weight - eprim_wt) / eprim_wt * 100\n",
    "print(f\"Weight Error: {wt_error}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msavefile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      2\u001b[0m     loaded_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(loaded_data)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.json'"
     ]
    }
   ],
   "source": [
    "with open(savefile, \"r\") as f:\n",
    "    loaded_data = json.load(f)\n",
    "print(loaded_data)\n",
    "currres = []\n",
    "loaded_data.append(\n",
    "    [\n",
    "        points_count,\n",
    "        no_centres,\n",
    "        mst_weight,\n",
    "        eprim_wt,\n",
    "        edgecount,\n",
    "        wt_error,\n",
    "        dcran_elapsed_time,\n",
    "        eprim_elapsed_time,\n",
    "        speedup,\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Save the updated dictionary back to the JSON file\n",
    "with open(savefile, \"w\") as f:\n",
    "    json.dump(loaded_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\n",
    "    \"Points\",\n",
    "    \"Centres\",\n",
    "    \"DCRAN Wt\",\n",
    "    \"prims Wt\",\n",
    "    \"Edge count\",\n",
    "    \"Acc(%)\",\n",
    "    \"DCRAN Time (s)\",\n",
    "    \"STMST Time (s)\",\n",
    "    \"Speedup\",\n",
    "]\n",
    "\n",
    "# Format the data as a table using tabulate\n",
    "table_str = tabulate(\n",
    "    loaded_data[-15:],\n",
    "    headers,\n",
    "    tablefmt=\"pipe\",\n",
    "    floatfmt=(\".0f\", \".0f\", \".1f\", \".1f\", \".0f\", \".2f\", \".2f\", \".2f\", \".2f\"),\n",
    ")\n",
    "print(table_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
